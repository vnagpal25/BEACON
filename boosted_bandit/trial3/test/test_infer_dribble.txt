% Running on host: VanshLaptop

% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.

% Calling ILPouterLoop from createRegressionOuterLooper.

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=0: args[N]=test/test_pos.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=1: args[N]=test/test_neg.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=2: args[N]=test/test_bk.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=3: args[N]=test/test_facts.txt

% Welcome to the WILL ILP/SRL systems.


% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.
% Reading background theory from dir: null
% Load '../recs_bk.txt'.

% Switching to VarIndicator = uppercase.

***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****


***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****

% [ LazyGroundClauseIndex ]  Building full index for mode/1 with 1 assertions.

%  Read the facts.
%  Have read 24 facts.
% Have read 265 examples from 'test' [test/test*].
% Have read 96 examples from 'test' [test/test*].

%  LearnOneClause initialized.

% The outer looper has been created.

% Initializing the ILP inner looper.

% NEW target:                 recommendation(A, B)
%  targetPred:                recommendation/2
%  targetArgTypes:            signature = [const, const], types = [+user_name, +item_name]
%  targets:                   [recommendation(A, B)]
%  targetPredicates:          [recommendation/2]
%  targetArgSpecs:            [[A[+user_name], B[+item_name]]]
%  variablesInTargets:        [[A, B]]

% Started collecting constants

% Collecting the types of constants.

% Looking at the training examples to see if any types of new constants can be inferred.
% Time to collect constants: 4 milliseconds
% Time to collect examples: 0 seconds

% Read 265 pos examples and 96 neg examples.
% Time to init learnOneClause: 6 milliseconds
% Old dirtrain/models/

% Have 265 'raw' positive examples and kept 265.
% Have 96 'raw' negative examples and kept 96.

% processing backup's for recommendation
%  POS EX = 265
%  NEG EX = 96

% Memory usage by WILLSetup (just counts # targets?):
%  |backupPosExamples| = 1
%  |backupNegExamples| = 1
%  |predicatesAsFacts| = 0
%  |addedToFactBase|   = 0

% Getting bRDN's target predicates.
% Did not learn a model for 'recommendation' this run.
%   loadModel (#0): train/models/bRDNs/Trees/recommendationTree0.tree
%   loadModel (#1): train/models/bRDNs/Trees/recommendationTree1.tree
%   loadModel (#2): train/models/bRDNs/Trees/recommendationTree2.tree
%   loadModel (#3): train/models/bRDNs/Trees/recommendationTree3.tree
%   loadModel (#4): train/models/bRDNs/Trees/recommendationTree4.tree
%   loadModel (#5): train/models/bRDNs/Trees/recommendationTree5.tree
%   loadModel (#6): train/models/bRDNs/Trees/recommendationTree6.tree
%   loadModel (#7): train/models/bRDNs/Trees/recommendationTree7.tree
%   loadModel (#8): train/models/bRDNs/Trees/recommendationTree8.tree
%   loadModel (#9): train/models/bRDNs/Trees/recommendationTree9.tree
%   loadModel (#10): train/models/bRDNs/Trees/recommendationTree10.tree
%   loadModel (#11): train/models/bRDNs/Trees/recommendationTree11.tree
%   loadModel (#12): train/models/bRDNs/Trees/recommendationTree12.tree
%   loadModel (#13): train/models/bRDNs/Trees/recommendationTree13.tree
%   loadModel (#14): train/models/bRDNs/Trees/recommendationTree14.tree
%   loadModel (#15): train/models/bRDNs/Trees/recommendationTree15.tree
%   loadModel (#16): train/models/bRDNs/Trees/recommendationTree16.tree
%   loadModel (#17): train/models/bRDNs/Trees/recommendationTree17.tree
%   loadModel (#18): train/models/bRDNs/Trees/recommendationTree18.tree
%   loadModel (#19): train/models/bRDNs/Trees/recommendationTree19.tree
%  Done loading 20 models.
File: test/advice.txt doesnt exist.Hence no advice loaded

% for recommendation |lookupPos| = 265
% for recommendation |lookupNeg| = 96
% getJointExamples: |pos| = 265, |neg| = 96

% Starting inference in bRDN.
% Trees = 20

% Starting getMarginalProbabilities.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for item/2.
% No Gibbs sampling needed during inference.
 (Arithmetic) Mean Probability Assigned to Correct Output Class: 245.399/361.00 = 0.679776

 The weighted count of positive examples = 265.000 and the weighted count of negative examples = 96.000

printExamples: Writing out predictions (for Tuffy?) on 361 examples for 'recommendation' to:
  test/results_recommendation.db
 and to:
  test/query_recommendation.db
%    No need to compress since small: test/query_recommendation.db

% Computing Area Under Curves.
%Pos=265
%Neg=96
%LL:-45.12679449963545
%LL:-220.14489639092463

% Running command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0
% WAITING FOR command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0
% DONE WAITING FOR command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0

%   AUC ROC   = 0.580700
%   AUC PR    = 0.769096
%   CLL	      = -0.609820
%   Precision = 0.771242 at threshold = 0.717
%   Recall    = 0.890566
%   F1        = 0.826620

% Total inference time (20 trees): 427 milliseconds.
